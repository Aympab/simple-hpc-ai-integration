{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_pb(path_to_pb):\n",
    "    with tf.compat.v1.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =\"/home/cea/am611608/source/simple-hpc/models/sampo-model/cas_test/nn/mutation_toy_case_best/savec_model.pb\"\n",
    "model = tf.saved_model.load(model_path)\n",
    "# import os\n",
    "# model = load_pb(os.path.join(model_path, \"saved_model.pb\")) #this won't work because \"freezing\" issues ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "model = keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running NN feed forward\n",
    "The input shape is `[?, 1, 2]` with `?` being the batch size.\n",
    "\n",
    "With `.pb` files, we can dynamically adapt the batch size using tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1, 2), dtype=float32, numpy=\n",
       "array([[[0.851226  , 0.24256265]],\n",
       "\n",
       "       [[0.308357  , 0.67497647]],\n",
       "\n",
       "       [[0.37940705, 0.24955785]],\n",
       "\n",
       "       [[0.7900673 , 0.35857797]],\n",
       "\n",
       "       [[0.35490656, 0.59782434]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform(shape=[1000000, 1, 2]) #this works\n",
    "x = tf.random.uniform(shape=[1, 1, 2]) #this works\n",
    "x = tf.random.uniform(shape=[1, 4, 2]) #this won't work because the input vec size is not [4, 2]\n",
    "x = tf.random.uniform(shape=[5, 1, 2]) #this works\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the feed forward pass, we will get `batch size` time our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1, 8), dtype=float32, numpy=\n",
       "array([[[9.3397111e-01, 9.3398947e-01, 6.6095054e-02, 7.1410370e-01,\n",
       "         8.1382418e-01, 2.0788598e-01, 2.1809448e-01, 7.5530356e-01]],\n",
       "\n",
       "       [[9.9986613e-01, 9.9986404e-01, 1.2493134e-04, 9.6699774e-01,\n",
       "         8.5918379e-01, 6.6183472e-01, 6.9125378e-01, 9.7201562e-01]],\n",
       "\n",
       "       [[9.7296405e-01, 9.7298741e-01, 2.7127773e-02, 7.1851879e-01,\n",
       "         7.3312771e-01, 1.6771740e-01, 1.7986509e-01, 7.6515841e-01]],\n",
       "\n",
       "       [[9.9792218e-01, 9.9795532e-01, 2.2155643e-03, 8.3640909e-01,\n",
       "         8.7968493e-01, 1.4069468e-01, 1.5559848e-01, 8.9056581e-01]],\n",
       "\n",
       "       [[9.9986303e-01, 9.9986476e-01, 1.3926625e-04, 9.5487618e-01,\n",
       "         8.6670578e-01, 5.4265457e-01, 5.7891345e-01, 9.6442497e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to visualize the execution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-5dc368ce35b1>:8: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message with type 'tensorflow.GraphDef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5dc368ce35b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mg_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# LOGDIR='/net/jabba/home0/am611608/source/simple-hpc/models/logs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message with type 'tensorflow.GraphDef'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "# import \n",
    "# tf.compat.v1.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    model_filename =os.path.join(model_path,'saved_model.pb')\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        g_in = tf.compat.v1.import_graph_def(graph_def)\n",
    "# LOGDIR='/net/jabba/home0/am611608/source/simple-hpc/models/logs'\n",
    "# train_writer = tf.compat.v1.summary.FileWriter(LOGDIR)\n",
    "# train_writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.6.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "import tensorboard\n",
    "tensorboard.__version__\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = tf.keras.models.load_model(model_path, compile=False)\n",
    "# kmodel.build((1,1,2))\n",
    "# kmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1, 8), dtype=float32, numpy=\n",
       "array([[[9.3397111e-01, 9.3398947e-01, 6.6095054e-02, 7.1410370e-01,\n",
       "         8.1382418e-01, 2.0788598e-01, 2.1809448e-01, 7.5530356e-01]],\n",
       "\n",
       "       [[9.9986613e-01, 9.9986404e-01, 1.2493134e-04, 9.6699774e-01,\n",
       "         8.5918379e-01, 6.6183472e-01, 6.9125378e-01, 9.7201562e-01]],\n",
       "\n",
       "       [[9.7296405e-01, 9.7298741e-01, 2.7127773e-02, 7.1851879e-01,\n",
       "         7.3312771e-01, 1.6771740e-01, 1.7986509e-01, 7.6515841e-01]],\n",
       "\n",
       "       [[9.9792218e-01, 9.9795532e-01, 2.2155643e-03, 8.3640909e-01,\n",
       "         8.7968493e-01, 1.4069468e-01, 1.5559848e-01, 8.9056581e-01]],\n",
       "\n",
       "       [[9.9986303e-01, 9.9986476e-01, 1.3926625e-04, 9.5487618e-01,\n",
       "         8.6670578e-01, 5.4265457e-01, 5.7891345e-01, 9.6442497e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90a5304d5ddb849f688847e42cd499e8e23d5bcdf9e01226f8a1998a3612e1a0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
